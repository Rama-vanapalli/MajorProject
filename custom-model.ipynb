{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de48f82",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-06T06:14:15.741057Z",
     "iopub.status.busy": "2024-02-06T06:14:15.740787Z",
     "iopub.status.idle": "2024-02-06T06:14:15.750905Z",
     "shell.execute_reply": "2024-02-06T06:14:15.750181Z"
    },
    "papermill": {
     "duration": 0.016805,
     "end_time": "2024-02-06T06:14:15.752804",
     "exception": false,
     "start_time": "2024-02-06T06:14:15.735999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435f6280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:14:15.760501Z",
     "iopub.status.busy": "2024-02-06T06:14:15.760243Z",
     "iopub.status.idle": "2024-02-06T06:14:30.419208Z",
     "shell.execute_reply": "2024-02-06T06:14:30.418365Z"
    },
    "papermill": {
     "duration": 14.665218,
     "end_time": "2024-02-06T06:14:30.421441",
     "exception": false,
     "start_time": "2024-02-06T06:14:15.756223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 06:14:17.849911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 06:14:17.850033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 06:14:18.003969: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0840ea5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:14:30.429712Z",
     "iopub.status.busy": "2024-02-06T06:14:30.429176Z",
     "iopub.status.idle": "2024-02-06T06:14:30.435828Z",
     "shell.execute_reply": "2024-02-06T06:14:30.434956Z"
    },
    "papermill": {
     "duration": 0.012811,
     "end_time": "2024-02-06T06:14:30.437841",
     "exception": false,
     "start_time": "2024-02-06T06:14:30.425030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acc7dd",
   "metadata": {
    "papermill": {
     "duration": 0.003087,
     "end_time": "2024-02-06T06:14:30.444119",
     "exception": false,
     "start_time": "2024-02-06T06:14:30.441032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8d3091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:14:30.451927Z",
     "iopub.status.busy": "2024-02-06T06:14:30.451389Z",
     "iopub.status.idle": "2024-02-06T06:14:34.101530Z",
     "shell.execute_reply": "2024-02-06T06:14:34.100669Z"
    },
    "papermill": {
     "duration": 3.656392,
     "end_time": "2024-02-06T06:14:34.103708",
     "exception": false,
     "start_time": "2024-02-06T06:14:30.447316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8948 images belonging to 3 classes.\n",
      "Found 557 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Data Preparation\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    '/kaggle/input/covidqu/Infection Segmentation Data/Infection Segmentation Data/Train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    '/kaggle/input/covidqu/Infection Segmentation Data/Infection Segmentation Data/Val',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84d29d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-06T06:14:34.112071Z",
     "iopub.status.busy": "2024-02-06T06:14:34.111788Z",
     "iopub.status.idle": "2024-02-06T07:38:31.060236Z",
     "shell.execute_reply": "2024-02-06T07:38:31.059100Z"
    },
    "papermill": {
     "duration": 5038.049977,
     "end_time": "2024-02-06T07:38:32.157345",
     "exception": false,
     "start_time": "2024-02-06T06:14:34.107368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1707200086.381884      88 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - ETA: 0s - loss: 0.8286 - accuracy: 0.5971 - f1_score: 0.5080\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55655, saving model to Custom_Model/model_epoch_01_train_acc_0.5971_val_acc_0.5566.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 117s 349ms/step - loss: 0.8286 - accuracy: 0.5971 - f1_score: 0.5080 - val_loss: 1.0770 - val_accuracy: 0.5566 - val_f1_score: 0.0199\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.7062 - accuracy: 0.6586 - f1_score: 0.6236\n",
      "Epoch 2: val_accuracy improved from 0.55655 to 0.60503, saving model to Custom_Model/model_epoch_02_train_acc_0.6586_val_acc_0.6050.h5\n",
      "280/280 [==============================] - 92s 323ms/step - loss: 0.7062 - accuracy: 0.6586 - f1_score: 0.6236 - val_loss: 0.9708 - val_accuracy: 0.6050 - val_f1_score: 0.1931\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.6750 - f1_score: 0.6541\n",
      "Epoch 3: val_accuracy improved from 0.60503 to 0.61041, saving model to Custom_Model/model_epoch_03_train_acc_0.6750_val_acc_0.6104.h5\n",
      "280/280 [==============================] - 91s 320ms/step - loss: 0.6568 - accuracy: 0.6750 - f1_score: 0.6541 - val_loss: 0.8834 - val_accuracy: 0.6104 - val_f1_score: 0.5703\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.6899 - f1_score: 0.6737\n",
      "Epoch 4: val_accuracy did not improve from 0.61041\n",
      "280/280 [==============================] - 91s 322ms/step - loss: 0.6305 - accuracy: 0.6899 - f1_score: 0.6737 - val_loss: 0.9306 - val_accuracy: 0.5853 - val_f1_score: 0.4646\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.5914 - accuracy: 0.7057 - f1_score: 0.6940\n",
      "Epoch 5: val_accuracy improved from 0.61041 to 0.67864, saving model to Custom_Model/model_epoch_05_train_acc_0.7057_val_acc_0.6786.h5\n",
      "280/280 [==============================] - 91s 323ms/step - loss: 0.5914 - accuracy: 0.7057 - f1_score: 0.6940 - val_loss: 0.7918 - val_accuracy: 0.6786 - val_f1_score: 0.6045\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.7095 - f1_score: 0.6978\n",
      "Epoch 6: val_accuracy did not improve from 0.67864\n",
      "280/280 [==============================] - 92s 323ms/step - loss: 0.5801 - accuracy: 0.7095 - f1_score: 0.6978 - val_loss: 0.8019 - val_accuracy: 0.6445 - val_f1_score: 0.6358\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7257 - f1_score: 0.7166\n",
      "Epoch 7: val_accuracy improved from 0.67864 to 0.68941, saving model to Custom_Model/model_epoch_07_train_acc_0.7257_val_acc_0.6894.h5\n",
      "280/280 [==============================] - 93s 328ms/step - loss: 0.5474 - accuracy: 0.7257 - f1_score: 0.7166 - val_loss: 0.7622 - val_accuracy: 0.6894 - val_f1_score: 0.6471\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.7231 - f1_score: 0.7131\n",
      "Epoch 8: val_accuracy did not improve from 0.68941\n",
      "280/280 [==============================] - 91s 318ms/step - loss: 0.5387 - accuracy: 0.7231 - f1_score: 0.7131 - val_loss: 0.7978 - val_accuracy: 0.6822 - val_f1_score: 0.6362\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.7512 - f1_score: 0.7421\n",
      "Epoch 9: val_accuracy improved from 0.68941 to 0.73609, saving model to Custom_Model/model_epoch_09_train_acc_0.7512_val_acc_0.7361.h5\n",
      "280/280 [==============================] - 93s 327ms/step - loss: 0.4966 - accuracy: 0.7512 - f1_score: 0.7421 - val_loss: 0.6921 - val_accuracy: 0.7361 - val_f1_score: 0.7263\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.7641 - f1_score: 0.7592\n",
      "Epoch 10: val_accuracy improved from 0.73609 to 0.75583, saving model to Custom_Model/model_epoch_10_train_acc_0.7641_val_acc_0.7558.h5\n",
      "280/280 [==============================] - 91s 320ms/step - loss: 0.4702 - accuracy: 0.7641 - f1_score: 0.7592 - val_loss: 0.6770 - val_accuracy: 0.7558 - val_f1_score: 0.7460\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.4392 - accuracy: 0.7735 - f1_score: 0.7709\n",
      "Epoch 11: val_accuracy did not improve from 0.75583\n",
      "280/280 [==============================] - 93s 329ms/step - loss: 0.4392 - accuracy: 0.7735 - f1_score: 0.7709 - val_loss: 0.7548 - val_accuracy: 0.7253 - val_f1_score: 0.7099\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.4086 - accuracy: 0.7871 - f1_score: 0.7853\n",
      "Epoch 12: val_accuracy did not improve from 0.75583\n",
      "280/280 [==============================] - 91s 322ms/step - loss: 0.4086 - accuracy: 0.7871 - f1_score: 0.7853 - val_loss: 0.7344 - val_accuracy: 0.7145 - val_f1_score: 0.7063\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.8000 - f1_score: 0.7987\n",
      "Epoch 13: val_accuracy did not improve from 0.75583\n",
      "280/280 [==============================] - 98s 346ms/step - loss: 0.3868 - accuracy: 0.8000 - f1_score: 0.7987 - val_loss: 0.7472 - val_accuracy: 0.6966 - val_f1_score: 0.6902\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8096 - f1_score: 0.8056\n",
      "Epoch 14: val_accuracy did not improve from 0.75583\n",
      "280/280 [==============================] - 92s 323ms/step - loss: 0.3651 - accuracy: 0.8096 - f1_score: 0.8056 - val_loss: 0.7769 - val_accuracy: 0.7235 - val_f1_score: 0.7170\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3389 - accuracy: 0.8221 - f1_score: 0.8205\n",
      "Epoch 15: val_accuracy improved from 0.75583 to 0.76661, saving model to Custom_Model/model_epoch_15_train_acc_0.8221_val_acc_0.7666.h5\n",
      "280/280 [==============================] - 92s 322ms/step - loss: 0.3389 - accuracy: 0.8221 - f1_score: 0.8205 - val_loss: 0.6765 - val_accuracy: 0.7666 - val_f1_score: 0.7652\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8271 - f1_score: 0.8250\n",
      "Epoch 16: val_accuracy improved from 0.76661 to 0.77020, saving model to Custom_Model/model_epoch_16_train_acc_0.8271_val_acc_0.7702.h5\n",
      "280/280 [==============================] - 92s 323ms/step - loss: 0.3282 - accuracy: 0.8271 - f1_score: 0.8250 - val_loss: 0.6747 - val_accuracy: 0.7702 - val_f1_score: 0.7725\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.8342 - f1_score: 0.8326\n",
      "Epoch 17: val_accuracy did not improve from 0.77020\n",
      "280/280 [==============================] - 93s 326ms/step - loss: 0.3181 - accuracy: 0.8342 - f1_score: 0.8326 - val_loss: 0.8533 - val_accuracy: 0.6571 - val_f1_score: 0.6156\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8293 - f1_score: 0.8283\n",
      "Epoch 18: val_accuracy did not improve from 0.77020\n",
      "280/280 [==============================] - 90s 315ms/step - loss: 0.3059 - accuracy: 0.8293 - f1_score: 0.8283 - val_loss: 0.7208 - val_accuracy: 0.7433 - val_f1_score: 0.7467\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8401 - f1_score: 0.8398\n",
      "Epoch 19: val_accuracy improved from 0.77020 to 0.77738, saving model to Custom_Model/model_epoch_19_train_acc_0.8401_val_acc_0.7774.h5\n",
      "280/280 [==============================] - 89s 313ms/step - loss: 0.2895 - accuracy: 0.8401 - f1_score: 0.8398 - val_loss: 0.6891 - val_accuracy: 0.7774 - val_f1_score: 0.7778\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.8517 - f1_score: 0.8501\n",
      "Epoch 20: val_accuracy did not improve from 0.77738\n",
      "280/280 [==============================] - 92s 325ms/step - loss: 0.2689 - accuracy: 0.8517 - f1_score: 0.8501 - val_loss: 0.7720 - val_accuracy: 0.7181 - val_f1_score: 0.7242\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.8609 - f1_score: 0.8606\n",
      "Epoch 21: val_accuracy did not improve from 0.77738\n",
      "280/280 [==============================] - 91s 321ms/step - loss: 0.2455 - accuracy: 0.8609 - f1_score: 0.8606 - val_loss: 0.7575 - val_accuracy: 0.7648 - val_f1_score: 0.7605\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.8590 - f1_score: 0.8579\n",
      "Epoch 22: val_accuracy did not improve from 0.77738\n",
      "280/280 [==============================] - 96s 337ms/step - loss: 0.2464 - accuracy: 0.8590 - f1_score: 0.8579 - val_loss: 0.7806 - val_accuracy: 0.7379 - val_f1_score: 0.7377\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8621 - f1_score: 0.8618\n",
      "Epoch 23: val_accuracy did not improve from 0.77738\n",
      "280/280 [==============================] - 92s 324ms/step - loss: 0.2440 - accuracy: 0.8621 - f1_score: 0.8618 - val_loss: 0.7735 - val_accuracy: 0.7756 - val_f1_score: 0.7742\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.8643 - f1_score: 0.8644\n",
      "Epoch 24: val_accuracy improved from 0.77738 to 0.78456, saving model to Custom_Model/model_epoch_24_train_acc_0.8643_val_acc_0.7846.h5\n",
      "280/280 [==============================] - 93s 327ms/step - loss: 0.2307 - accuracy: 0.8643 - f1_score: 0.8644 - val_loss: 0.8262 - val_accuracy: 0.7846 - val_f1_score: 0.7834\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.8662 - f1_score: 0.8662\n",
      "Epoch 25: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 94s 326ms/step - loss: 0.2280 - accuracy: 0.8662 - f1_score: 0.8662 - val_loss: 0.9234 - val_accuracy: 0.7074 - val_f1_score: 0.7048\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.8652 - f1_score: 0.8645\n",
      "Epoch 26: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 322ms/step - loss: 0.2283 - accuracy: 0.8652 - f1_score: 0.8645 - val_loss: 0.8479 - val_accuracy: 0.7720 - val_f1_score: 0.7794\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.8698 - f1_score: 0.8694\n",
      "Epoch 27: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 322ms/step - loss: 0.2087 - accuracy: 0.8698 - f1_score: 0.8694 - val_loss: 0.8828 - val_accuracy: 0.7828 - val_f1_score: 0.7830\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.8703 - f1_score: 0.8699\n",
      "Epoch 28: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 97s 340ms/step - loss: 0.2056 - accuracy: 0.8703 - f1_score: 0.8699 - val_loss: 0.9388 - val_accuracy: 0.7630 - val_f1_score: 0.7635\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.8666 - f1_score: 0.8670\n",
      "Epoch 29: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 89s 314ms/step - loss: 0.2128 - accuracy: 0.8666 - f1_score: 0.8670 - val_loss: 0.9729 - val_accuracy: 0.7307 - val_f1_score: 0.7337\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.8766 - f1_score: 0.8761\n",
      "Epoch 30: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 94s 331ms/step - loss: 0.2066 - accuracy: 0.8766 - f1_score: 0.8761 - val_loss: 0.8314 - val_accuracy: 0.7630 - val_f1_score: 0.7662\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.8811 - f1_score: 0.8813\n",
      "Epoch 31: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 93s 328ms/step - loss: 0.1916 - accuracy: 0.8811 - f1_score: 0.8813 - val_loss: 0.9591 - val_accuracy: 0.7397 - val_f1_score: 0.7428\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.8745 - f1_score: 0.8743\n",
      "Epoch 32: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 93s 327ms/step - loss: 0.1992 - accuracy: 0.8745 - f1_score: 0.8743 - val_loss: 0.9215 - val_accuracy: 0.7774 - val_f1_score: 0.7796\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.8847 - f1_score: 0.8844\n",
      "Epoch 33: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 93s 329ms/step - loss: 0.1887 - accuracy: 0.8847 - f1_score: 0.8844 - val_loss: 1.0848 - val_accuracy: 0.7127 - val_f1_score: 0.7157\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.8797 - f1_score: 0.8792\n",
      "Epoch 34: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 99s 348ms/step - loss: 0.1956 - accuracy: 0.8797 - f1_score: 0.8792 - val_loss: 0.9352 - val_accuracy: 0.7379 - val_f1_score: 0.7409\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.8816 - f1_score: 0.8803\n",
      "Epoch 35: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 90s 317ms/step - loss: 0.1960 - accuracy: 0.8816 - f1_score: 0.8803 - val_loss: 1.4938 - val_accuracy: 0.7325 - val_f1_score: 0.7290\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.8781 - f1_score: 0.8777\n",
      "Epoch 36: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 93s 323ms/step - loss: 0.1973 - accuracy: 0.8781 - f1_score: 0.8777 - val_loss: 0.9405 - val_accuracy: 0.7576 - val_f1_score: 0.7515\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.8814 - f1_score: 0.8815\n",
      "Epoch 37: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 324ms/step - loss: 0.1897 - accuracy: 0.8814 - f1_score: 0.8815 - val_loss: 1.0749 - val_accuracy: 0.7612 - val_f1_score: 0.7551\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.8819 - f1_score: 0.8816\n",
      "Epoch 38: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 321ms/step - loss: 0.1849 - accuracy: 0.8819 - f1_score: 0.8816 - val_loss: 0.9855 - val_accuracy: 0.7756 - val_f1_score: 0.7683\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.8805 - f1_score: 0.8804\n",
      "Epoch 39: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 324ms/step - loss: 0.1733 - accuracy: 0.8805 - f1_score: 0.8804 - val_loss: 1.1511 - val_accuracy: 0.7433 - val_f1_score: 0.7381\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.8892 - f1_score: 0.8885\n",
      "Epoch 40: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 94s 330ms/step - loss: 0.1793 - accuracy: 0.8892 - f1_score: 0.8885 - val_loss: 1.1100 - val_accuracy: 0.7487 - val_f1_score: 0.7504\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.8862 - f1_score: 0.8858\n",
      "Epoch 41: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 324ms/step - loss: 0.1820 - accuracy: 0.8862 - f1_score: 0.8858 - val_loss: 1.1976 - val_accuracy: 0.7648 - val_f1_score: 0.7597\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.8860 - f1_score: 0.8849\n",
      "Epoch 42: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 322ms/step - loss: 0.1800 - accuracy: 0.8860 - f1_score: 0.8849 - val_loss: 1.3240 - val_accuracy: 0.7433 - val_f1_score: 0.7418\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.8866 - f1_score: 0.8854\n",
      "Epoch 43: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 95s 336ms/step - loss: 0.1786 - accuracy: 0.8866 - f1_score: 0.8854 - val_loss: 1.3671 - val_accuracy: 0.7092 - val_f1_score: 0.7087\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.8753 - f1_score: 0.8755\n",
      "Epoch 44: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 91s 322ms/step - loss: 0.2046 - accuracy: 0.8753 - f1_score: 0.8755 - val_loss: 1.1998 - val_accuracy: 0.7522 - val_f1_score: 0.7523\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.8844 - f1_score: 0.8844\n",
      "Epoch 45: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 91s 321ms/step - loss: 0.1700 - accuracy: 0.8844 - f1_score: 0.8844 - val_loss: 1.4299 - val_accuracy: 0.7397 - val_f1_score: 0.7325\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.8843 - f1_score: 0.8832\n",
      "Epoch 46: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 325ms/step - loss: 0.1786 - accuracy: 0.8843 - f1_score: 0.8832 - val_loss: 1.2039 - val_accuracy: 0.7361 - val_f1_score: 0.7306\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.8889 - f1_score: 0.8885\n",
      "Epoch 47: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 94s 330ms/step - loss: 0.1737 - accuracy: 0.8889 - f1_score: 0.8885 - val_loss: 1.1136 - val_accuracy: 0.7379 - val_f1_score: 0.7409\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.8839 - f1_score: 0.8840\n",
      "Epoch 48: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 98s 339ms/step - loss: 0.1797 - accuracy: 0.8839 - f1_score: 0.8840 - val_loss: 1.3961 - val_accuracy: 0.7451 - val_f1_score: 0.7472\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.8873 - f1_score: 0.8870\n",
      "Epoch 49: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 326ms/step - loss: 0.1736 - accuracy: 0.8873 - f1_score: 0.8870 - val_loss: 1.3882 - val_accuracy: 0.7558 - val_f1_score: 0.7500\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.8831 - f1_score: 0.8832\n",
      "Epoch 50: val_accuracy did not improve from 0.78456\n",
      "280/280 [==============================] - 92s 324ms/step - loss: 0.1754 - accuracy: 0.8831 - f1_score: 0.8832 - val_loss: 1.4984 - val_accuracy: 0.7379 - val_f1_score: 0.7391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = 'Custom_Model/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the model at every improved epoch\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'model_epoch_{epoch:02d}_train_acc_{accuracy:.4f}_val_acc_{val_accuracy:.4f}.h5'),\n",
    "    monitor='val_accuracy',  # metric to monitor\n",
    "    verbose=1,  # verbosity - 0 or 1\n",
    "    save_best_only=True,  # Save only the best model according to the monitored metric\n",
    "    mode='max',  # Since we are monitoring accuracy, higher is better\n",
    "    save_weights_only=False  # Save the full model, not just the weights\n",
    ")\n",
    "\n",
    "# Create a custom CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (1, 1), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', name='fc1'))\n",
    "model.add(Dense(32, activation='relu', name='fc2'))\n",
    "model.add(Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_score])\n",
    "\n",
    "# Adjust the `workers` parameter as necessary\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[checkpoint],\n",
    "    use_multiprocessing=True,  # Enable multiprocessing\n",
    "    workers=4  # Number of workers to use. Adjust as per your CPU cores.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b21d2",
   "metadata": {
    "papermill": {
     "duration": 1.204854,
     "end_time": "2024-02-06T07:38:34.507691",
     "exception": false,
     "start_time": "2024-02-06T07:38:33.302837",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8200bd4",
   "metadata": {
    "papermill": {
     "duration": 1.201976,
     "end_time": "2024-02-06T07:38:36.845815",
     "exception": false,
     "start_time": "2024-02-06T07:38:35.643839",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c99d3d44",
   "metadata": {
    "papermill": {
     "duration": 1.184,
     "end_time": "2024-02-06T07:38:39.168481",
     "exception": false,
     "start_time": "2024-02-06T07:38:37.984481",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1262f57",
   "metadata": {
    "papermill": {
     "duration": 1.191398,
     "end_time": "2024-02-06T07:38:41.504912",
     "exception": false,
     "start_time": "2024-02-06T07:38:40.313514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1210221,
     "sourceId": 3122958,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5073.267514,
   "end_time": "2024-02-06T07:38:46.071372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-06T06:14:12.803858",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
